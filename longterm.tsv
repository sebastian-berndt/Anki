
lineare Abbildung	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume. Eine Abbildung \(f: V \rightarrow W\) hei\ss t \(K\)-linear (kurz: linear), wenn fuer alle \(v,w \in V\) und \(\lambda \in K\) die Gleichungen \begin{enumerate} \item \(f(\lambda v)=\lambda f(v)\), \item \(f(v+w) = f(v) + f(w)\), \end{enumerate} gelten. Die Menge aller dieser Abbildungen bezeichnen wir mit \(L(V,W)\).
Homomorphismus	Eine lineare Abbildung \(f: W \rightarrow V\) wird Homomorphismus genannt.
Isomorphmismus	Ein bijektiver Homomorphismus hei\ss t Isomorphismus.
Endomorphismus	Eine Abbildung \(f \in L(V,V)\) hei\ss t Endomorphismus.
Automorphmismus	Ein bijektiver Endomorphismus hei\ss t Automorphismus.
Kern	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\), dann hei\ss t: \[Kern(f):=\{v \in V|f(v)=0\}.\]
Bild	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\), dann hei\ss t: \[Bild(f):=\{f(v)|v \in V\} \subseteq W.\]
Urbild	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\). Dann definiert man das Urbild von \(w\) in \(V\) als \[f^{-1}(w):=f^{-1}({w})=\{w \in V|f(v)=w\}.\]

Darstellende Matrix eines Homomorphismus	Die durch \[(f(v_1),\ldots,f(v_m)) = (w_1,\ldots,w_n)A\] eindeutig bestimmte Matrix hei\ss t die Matrixdarstellung oder darstellende Matrix von \(f \in L(V,W)\) bzgl. der Basen \(B_1=\{v_1,\ldots,v_m\}\) von \(V\) und \(B_2=\{w_1,\ldots,w_n\}\) von \(W\). Wir bezeichnen diese Matrix mit \([f]_{B_1,B_2}\).
Koordinatenabbildung	Ist \(B=\{v_1,\ldots,v_n\}\) eine Basis des \(K\)-Vektorraums \(V\), so ist die Abbildung \[\phi_B:V \rightarrow K^{n,1}, v=\lambda_1 v_1 + \ldots + \lambda_n v_n \mapsto \phi_B(v):=\begin{bmatrix}\lambda_1\\\vdots\\\lambda_n\end{bmatrix},\] ein Isomorphismus, den wir die Koordinatenabbildung von \(V\) bzgl. der Basis \(B\) nennen.
Linearform	Ist \(V\) ein \(K\)-Vektorraum, so nennen wir eine Abbildung \(f \in L(V,K)\) eine Linearform auf \(V\).
Dualraum	Ist \(V\) ein \(K\)-Vektorraum. Den \(K\)-Vektorraum \(V^*:=L(V,K)\) nennen wir den Dualraum von \(V\).
Duale Basis	Sei \(V\) ein \(n\)-dimensionaler \(K\)-Vektorraum mit einer gegebenen Basis \(B = \{v_1,\ldots,v_n\}\). Dann gibt es genau eine Basis \(B^*=\{v_1^*,\ldots,v_n^*\}\) von \(V^*\) mit der Eigenschaft: \[v_j^*(v_j)=\delta_{ij}, \quad i,j=1,\ldots,n.\] Wir nennen \(B^*\) die zu \(B\) duale Basis \(V^*\).
Duale Abbildung	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume mit ihren jeweiligen Dualraeumen \(V^*,W^*\) und sei \(f \in L(V,W)\). Dann hei\ss t \[f^*:W^* \rightarrow V^*, \quad h \mapsto h \circ f,\] also \(f^*(h)=h \circ f\) fuer alle \(h \in W^*\), die zu \(f\) duale Abbildung.
Bilinearform	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume. Eine Abbildung \(\beta : V \times W \rightarrow K\) hei\ss t Bilinearform auf \(V \times W\), wenn \begin{enumerate} \item \(\beta (v_1 + v_2,w) = \beta (v_1,w) + \beta(v_2,w),\) \item \(\beta (v,w_1 +w_2)= \beta (v,w_1)+ \beta (v,w_2),\) \item \(\beta (\lambda v,w)=\beta (v, \lambda w)= \lambda \beta(v,w),\) \end{enumerate} fuer alle \(v,v_1,v_2 \in V, w,w_1,w_2 \in W\) und \(\lambda \in K\) gilt.
Nicht ausgeartet in der ersten Variablen	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartet in der ersten Variablen, wenn aus \(\beta(v,w)=0\) fuer alle \(w \in W\) folgt, dass \(v=0\) ist.
Nicht ausgeartet in der zweiten Variablen	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartet in der zweiten Variablen, wenn aus \(\beta(v,w)=0\) fuer alle \(v \in W\) folgt, dass \(w=0\) ist.
Nicht ausgeartete Bilinearform	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartete Bilinearform, falls \(\beta\) in beiden Variablen nicht ausgeartet ist.
Duales Raumpaar	Ist \(\beta\) eine nicht ausgeartete Bilinearform auf \(V \times W\), so nennen wir die Raeume \(V,W\) ein duales Paar von Raeumen oder duales Raumpaar von \(\beta\).
Symmetrische Bilinearform	Eine Bilinearform \(\beta\) auf \(V\) hei\ss t symmetrisch, wenn \(\beta (v,w)= \beta (w,v)\) fuer alle \(v,w \in V\) gilt.
Darstellende Matrix einer Bilinearform	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume mit Basen \(B_1=\{v_1,\ldots,v_m\}\) und \(B_2=\{w_1,\ldots,w_n\}\). Ist \(\beta\) eine Bilinearform auf \(V \times W\), so hei\ss t \[[\beta]_{B_1 \times B_2}=[b_{ij}] \in K^{n,m}, \quad b_{ij}:=\beta (v_j,w_i),\] die Matrixdarstellung oder darstellende Matrix von \(\beta\) bzgl. der Basen \(B_1\) und \(B_2\).
Kongruente Matrizen	Falls fuer zwei Matrizen \(A,B \in K^{n,n}\) eine Matrix \(Z \in GL_n(K)\) mit \(B=Z^T AZ\) existiert, so hei\ss en \(A\) und \(B\) kongruent.
Sesquilinearform	Seien \(V\) und \(W\) zwei \(\mathbb{C}\)-Vektorraeume. Eine Abbildung \(s: V \times W \rightarrow \mathbb{C}\) hei\ss t Sesquilinearform auf \(V \times W\), wenn \begin{enumerate} \item \(s(v_1 +v_2,w)=s(v_1,w)+s(v_2,w),\) \item \(s(\lambda v,w) = \lambda s(v,w),\) \item \(s(v,w_1+w_2)=s(v,w_1)+s(v,w_2),\) \item \(s(v,\lambda w)=\bar{\lambda} s(v,w),\) \end{enumerate} fuer alle \(v,v_1,v_2 \in V, w,w_1,w_2 \in W\) und \(\lambda \in \mathbb{C}\) gilt.
Hermitesche Sesquilinearform	Eine Sesquilinearform \(s\) auf \(V\) hei\ss t hermitesch, wenn \(s(v,w)=\overline{s(w,v)}\) fuer alle \(v, w \in V\) gilt.
Hermitesche Matrix	Ist \(A= [a_{ij}] \in \mathbb{C}^{n,m},\) so ist die hermitesch Transponierte von \(A\) die Matrix \[A^H:=[\bar{a}_{ij}]^T \in \mathbb{C}^{m,n}.\] Ist \(A=A^H\), so nennen wir \(A\) eine hermitesche Matrix.
Darstellende Matrix einer Sesquilinearform	Seien \(V\) und \(W\) zwei \(\mathbb{C}\)-Vektorraeume mit Basen \(B_1 = \{v_1,\ldots,v_m\}\) und \(B_2=\{w_1,\ldots,w_n\}\). Ist \(s\) eine Sesquilinearform auf \(V \times W\), so hei\ss t \[[s]_{B_1 \times B_2}=[b_{ij}] \in \mathbb{C}^{n,m}, \quad b_{ij}:=s(v_j,w_i),\] die Matrixdarstellung oder die darstellende Matrix von \(s\) bzgl. der Basen \(B_1\) und \(B_2\).

Skalarprodukt/inneres Produkt	Sei \(V\) ein \(K\)-Vektorraum, wobei entweder \(K=\mathbb{R}\) oder \(K=\mathbb{C}\) gelten soll. Eine Abbildung \[\langle \cdot,\cdot \rangle:V \times V \rightarrow K, \quad (v,w) \mapsto \langle v,w \rangle,\] hei\ss t Skalarprodukt oder inneres Produkt auf \(V\), wenn gilt: \begin{enumerate} \item Ist \(K = \mathbb{R}\), so ist \(\langle \cdot,\cdot \rangle\) eine symmetrische Bilinearform. Ist \(K=\mathbb{C}\), so ist \(\langle \cdot,\cdot \rangle\) eine hermitische Sesquilinearform. \item \(\langle \cdot,\cdot \rangle\) ist positiv definit, d.h. es gilt \(\langle v,v \rangle \geq 0\) fuer alle \(v \in V\) mit Gleichheit genau dann, wenn \(v=0\) ist.\end{enumerate}
Euklidischer Vektorraum	Ein \(\mathbb{R}\)-Vektorraum mit einem Skalarprodukt hei\ss t euklidischer Vektorraum.
Unitaerer Vektorraum	Ein \(\mathbb{C}\)-Vektorraum mit einem Skalarprodukt hei\ss t unitaerer Vektorraum.
Norm	Sei \(V\) ein \(K\)-Vektorraum, wobei entweder \(K=\mathbb{R}\) oder \(K=\mathbb{C}\) gelteen soll. Eine Abbildung \[\|\cdot \|:V \rightarrow \mathbb{R}, \quad v \mapsto \|v\|,\] hei\ss t Norm auf \(V\), wenn fuer alle \(v,w \in V\) und \(\lambda \in K\) gilt: \begin{enumerate} \item \(\|\lambda v\|=|\lambda| \cdot \|v\|.\) \item \(\|v\| \geq 0\) mit Gleichung genau dann, wenn \(v =0\) ist. \item \(\|v+w\| \leq \|v\| +\|w\|.\) \end{enumerate}
Normierter Raum	Ein \(K\)-Vektorraum, auf dem eine Norm definiert ist, hei\ss t normierter Raum.
Standardskalarprodukt des \(\mathbb{R}^{n,1}\)	Auf dem Vektorraum \(\mathbb{R}^{n,1}\) ist \[\langle v,w \rangle := w^Tv\] ein Skalarprodukt, welches das Standardskalarprodukt des \(\mathbb{R}^{n,1}\) genannt wird.
Standardskalarprodukt des \(\mathbb{C}^{n,1}\)	Auf dem Vektorraum \(\mathbb{C}^{n,1}\) ist \[\langle v,w \rangle := w^Hv\] ein Skalarprodukt, welches das Standardskalarprodukt des \(\mathbb{C}^{n,1}\) genannt wird.
Euklidische Norm des \(\mathbb{R}^{n,1}\)	Ist \(\langle \cdot,\cdot \rangle\) das Standardskalarprodukt des \(\mathbb{R}^{n,1}\), dann ist durch \[\|v\|:=\langle v,v \rangle ^{1/2}=(v^Tv)^{1/2}\] eine Norm definiert, die man die euklidische Norm des \(\mathbb{R}^{n,1}\) nennt.
Euklidische Norm des \(\mathbb{C}^{n,1}\)	Ist \(\langle \cdot,\cdot \rangle\) das Standardskalarprodukt des \(\mathbb{C}^{n,1}\), dann ist durch \[\|v\|:=\langle v,v \rangle ^{1/2}=(v^Hv)^{1/2}\] eine Norm definiert, die man die euklidische Norm des \(\mathbb{C}^{n,1}\) nennt.

Orthogonale Vektoren	Sei \(V\) ein euklidischer oder ein unitaerer Vektorraum mit dem Skalarprodukt \(\langle \cdot,\cdot \rangle\). Zwei Vektoren \(v,w \in V\) hei\ss en orthogonal bzgl. des gegebenen Skalarprodukts \(\langle \cdot,\cdot \rangle\), wenn \(\langle v,w \rangle =0\) gilt.
Orthogonalbasis	Eine Basis \(\{v_1,\cdots,v_j\}\) hei\ss t Orthogonalbasis, wenn \[\langle v_i,v_j \rangle =0, \quad i,j=1,\cdots,n \text{ und } i \neq j,\] gilt.
Orthonormalbasis	Eine Basis \(\{v_1,\cdots,v_j\}\) hei\ss t Orthonormalbasis, wenn \[\langle v_i,v_j \rangle =0, \quad i,j=1,\cdots,n \text{ und } i \neq j,\] gilt, sowie \[\|v_i\|=1, \quad i=1,\cdots,n,\] wobei \(\|v\|=\langle v,v \rangle ^{1/2}\) die vom Skalarprodukt induzierte Norm ist, so hei\ss t \(\{v_1,\cdots,v_j\}\) Orthogonalbasis von \(V\). Fuer eine Orthonormalbasis gilt also \(\langle v_i,v_j\rangle = \delta _{ij}.\)
Orthogonale Matrix	Eine Matrix \(Q \in \mathbb{R}^{n,n}\), deren Spalten eine Orthonormalbasis bzgl. des Standardskalarprodukts des \(\mathbb{R}^{n,1}\) bilden, hei\ss t orthogonale Matrix.
Unitaere Matrix	Eine Matrix \(Q \in \mathbb{C}^{n,n}\), deren Spalten eine Orthonormalbasis bzgl. des Standardskalarprodukts des \(\mathbb{C}^{n,1}\) bilden, hei\ss t unitaere Matrix.
Orthogonales Komplement	Sei \(V\) ein euklidischer oder ein unitaerer Vektorraum mit dem Skalarprodukt \(\langle \cdot, \cdot \rangle\) und sei \(U \subseteq V\) ein Unterraum. Dann hei\ss t \[U^{\bot}:=\{v \in V|\langle v,u \rangle =0 \text{ fuer alle } u \in U\}\] das orthogonale Komplement von \(U\) (in \(V\)).
Vektorprodukt/Kreuzprodukt	Das Vektorprodukt oder Kreuzprodukt im \(\mathbb{R}^{3,1}\) ist die Abbildung \[\mathbb{R}^{3,1} \times \mathbb{R}^{3,1} \rightarrow \mathbb{R}^{3,1} , \quad (v,w) \mapsto v \times w,\] mit \(v \times w := [v_2w_3-v_3w_2, v_3w_1-v_1w_3, v_1w_2-v_2w_1]^T\) fuer \(v=[v_1,v_2,v_2]^T, w=[w_1,w_2,w_3]^T \in \mathbb{R}^{3,1}\).

Adjungierte Abbildung	Ist \(V\) ein endlichdimensionaler euklidischer oder unitaerer Vektorraum mit dem Skalarpprodukt \(\langle \cdot,\cdot \rangle\), so gibt es zu jeder Abbildung \(f \in L(V,V)\) eine eindeutig bestimmte Abbildung \(f^{ad} \in L(V,V)\) fuer die \[\langle f(v),w \rangle = \langle v,f^{ad}(w)\rangle \quad \text{ und } \quad \langle v,f(w) \rangle = \langle f^{ad}(v),w \rangle\] fuer alle \(v,w \in V\) gilt. Dann nennt man die Abbildung \(f^{ad}\) die Adjungierte von \(f\) bzgl. \(\langle \cdot, \cdot \rangle\).
Selbstadjungierte Endomorphismus	Sei \(V\) ein endlichdimensionaler euklidischer oder unitÃ¤rer Vektorraum. Eine Abbildung \(f \in L(V,V)\) hei\ss t selbstadjungiert, wenn gilt: \[f = f^{ad}\]

Eigenwert	Sei \(V\) ein \(K\)-Vektorraum und sei \(f \in L(V,V).\) Falls fuer ein \(v \in V \setminus \{0\}\)  und ein \(\lambda \in K\) die Gleichung \[f(v)=\lambda v\] gilt, so nennt man \(\lambda\) einen Eigenwert von \(f\) und \(v\) einen zum Eigenwert \(\lambda\) gehoerenden Eigenvektor von \(f\).
Eigenvektor	Sei \(V\) ein \(K\)-Vektorraum und sei \(f \in L(V,V).\) Falls fuer ein \(v \in V \setminus \{0\}\)  und ein \(\lambda \in K\) die Gleichung \[f(v)=\lambda v\] gilt, so nennt man \(\lambda\) einen Eigenwert von \(f\) und \(v\) einen zum Eigenwert \(\lambda\) gehoerenden Eigenvektor von \(f\).
Eigenraum	Sind \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\), so hei\ss t der Unterraum \[V_f(\lambda):= Kern(\lambda Id_V - f)\] der Eigenraum von \(f\) zum Eigenwert \(\lambda\).
Geometrische Vielfachheit	Sind \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\), so hei\ss t \[g(\lambda, f):=dim(V_f(\lambda)\] die geometrische Vielfachheit des Eigenwertes \(\lambda\) von \(f\).
\(f\)-invarianter Unterraum	Sei \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\) und \(U \subseteq V\) ein Unterraum. Gilt \(f(U) \subseteq U\), also \(f(u) \in U\) fuer alle \(u \in U\), so hei\ss t \(U\) ein \(f\)-invarianter Unterraum von \(V\).
Charakteristisches Polynom	Sind \(n \in \mathbb{N}, V\) ein \(n\)-dimensionaler \(K\)-Vektorraum mit Basis \(B\) und \(f \in L(V,V),\) dann nennen wir \[P_f := \det(t I_n -[f]_{B,B}) \in K[t]\] das charakteristische Polynom von \(f\).
Algebraische Vielfachheit	Sei \(V\) ein endlichdimensionaler \(K\)-Vektorraum, \(f \in f(V,V)\) und sei \(\lambda \in K\) ein Eigenwert von \(f\). Hat das charakteristische Polynom die Form \[P_f = (t-\lambda)^d *g\] fuer ein \(g \in K[t]\) mit \(g(\lambda) \neq 0,\) so nennen wir \(d\) die algebraische Vielfachheit des Eigenwerts \(\lambda\) von \(f\). Wir bezeichnen diese mit \(a(\lambda,f)\).
Diagonalisierbar	Sei \(V\) ein endlichdimensionaler \(K\)-Vektorraum. Ein Endomorphismus \(f \in L(V,V)\) hei\ss t diagonalisierbar, wenn es eine Basis \(B\) von \(V\) gibt, so dass \([f]_{B,B}\) eine Diagonalmatrix ist.
Schur-Form einer Matrix	Ist \(A \in \mathbb{C}^{n,n}\), so gibt es eine unitaere Matrix \(Q \in C^{n,n}\) und eine obere Dreiecksmatrix \(R \in \mathbb{C}^{n,n}\) mit \(A=QRQ^H\). Die Matrix \(R\) nennen wir eine Schur-Form von \(A\).


Teiler	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Wenn es fuer zwei Polynome \(p,s \in K[t]\) ein Polynom \(q \in K[t]\) mit \(p=s*q\) gibt, dann hei\ss t \(s\) ein Teiler von \(p\) und wir schreiben \(s|p\) (s teilt p).
teilerfremde Polynome	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Zwei Polynome \(p,s \in K[t]\) hei\ss en teilerfremd, wenn aus \(q|p\) und \(q|s\) fuer ein \(q \in K[t]\) stets folgt, dass \(q\) ein kostantes Polynom ist.
Irreduzibel/Reduzibel	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Ein nicht-konstantes Polynom \(p \in K[t]\) hei\ss t irreduzibel (ueber \(K\)), wenn aus \(p=s*q\) fuer zwei Polynome \(s,q \in K[t]\) folgt, dass \(s\) oder \(q\) ein konstantes Polynom ist. Falls es zwei nicht-konstante Polynome \(s,q \in K[t]\) mit \(p=s*q\) gibt, so hei\ss t \(p\) reduzibel (ueber K)
Vielfachheit	Seien \(p \in K[t]\) und \(\lambda \in K\) eine Nullstelle von \(p\). Dann ist die Vielfachheit der Nullstelle \(\lambda\) die eindeutig bestimmte natuerliche Zahl \(m\), so dass \(p=(t-\lambda )^m*q\) fuer ein Polynom \(q \in K[t]\) mit \(q(\lambda) \neq 0\) ist.

Normaler Endomorphismus	Sei \(V\) ein endlichdimensionaler euklidischer oder unitaerer Vektorraum. Ein Endomorphismus \(f \in L(V,V)\) hei\ss t normal, wenn \(f \circ f^{ad}=f^{ad} \circ f\) gilt.
Normale Matrix	 Eine Matrix \(A \in \mathbb{R}^{n,n}\) oder \(A \in \mathbb{C}^{n,n}\) hei\ss t normal, wenn \(A^TA =AA^T\) bzw. \(A^HA=AA^H\) gilt.
Traegheitsindex einer Matrix	Ist \(A \in \mathbb{R}^{n,n}\) symmetrisch oder \(A \in \mathbb{C}^{n,n}\) hermitesch mit \(n_+\) positiven, \(n_-\) negativen und \(n_0\) Null Eigenwerten, dann hei\ss t der Tripel \((n_+,n_-,n_0)\) der Traegheitsindex von \(A\).
Definitheit	Eine reelle symmetrische oder komplex hermitesche \((n \times n)\)-Matrix \(A\) hei\ss t \begin{description} \item[positiv semidefinit,]wenn \(v^HAv \geq 0\) fuer alle \(v \in \mathbb{R}^{n,1}\) bzw. \(v \in \mathbb{C}^{n,1}\) gilt, \item[positiv definit,]wenn \(v^HAv > 0\) fuer alle \(v \in \mathbb{R}^{n,1} \setminus \{0\}\) bzw. \(v \in \mathbb{C}^{n,1}\setminus \{0\}\) gilt, \item[negativ semidefinit,]wenn \(v^HAv \leq 0\) fuer alle \(v \in \mathbb{R}^{n,1}\) bzw. \(v \in \mathbb{C}^{n,1}\) gilt, \item[negativ definit,]wenn \(v^HAv < 0\) fuer alle \(v \in \mathbb{R}^{n,1} \setminus \{0\}\) bzw. \(v \in \mathbb{C}^{n,1}\setminus \{0\}\) gilt. \end{description}
