Differenzierbar in \(x_0\) (Verallgemeinert auf normierte Vektorraeume)	Seien \(E\) und \(F\) normierte Vektorraeume. Dann heisst \(f: \Omega \subseteq E \rightarrow F,\ \Omega\) offen, in \(x_0 \in \Omega\) differenzierbar, wenn es eine lineare Abbildung \(A: E \rightarrow F\) mit \[\lim \limits_{x \rightarrow x_0} \frac{\|f(x)-\{f(x_0)+A(x-x_0)\}\|_{F}}{\|x-x_0\|_{E}}}\] gibt.
Satz 2.2	Ist \(f: \Omega \subseteq E \rightarrow F\) in \(x_0\) differenzierbar, so ist die Ableitung von \(f\) in \(x_0\) eindeutig bestimmt. Sie wird mit \(f'(x_0)\) bezeichnet.
Satz 2.4	Ist \(f\) in \(x_0\) differenzierbar und \(f'(x_0)\) stetig, so ist \(f\) in \(x_0\) stetig.
Satz 2.6	Eine lineare Abbildung \(A: E \rightarrow F\) ist genau dann auf ganz \(E\) stetig, wenn sie in irgendeinem \(x_0 \in E\) stetig ist, und dies ist genau dann der Fall, wenn \(A\) beschraenkt ist, das hei√üt, es eine Konstante \(C\) mit \[\|Av\|_{F} \leq C\|v\|_{E}\] fuer alle \(v \in E\) gibt.
Satz 2.7	Durch den Ausdruck \[\|A\|_{E \rightarrow F} := \sup_{\|v\|_E=1}\|Av\|_F\] wird eine Norm auf dem Vektorraum \(L(E,F)\) aller beschraenkten linearen Abbildungen von \(E\) nach \(F\) definiert. Fuer \(v \in E\) ist \[\|Av\|_{F} \leq \|A\|_{E \rightarrow F} \|v\|_{E}.\] Der Ausdruck \(\|A\|_{E \rightarrow F}\) wird als Operatornorm von A bezeichnet.
Operatornorm	Der Ausdruck \[\|A\|_{E \rightarrow F} := \sup_{\|v\|_{E}=1}\|Av\|_{F}\] wird als Operatornorm von \(A\) bezeichnet.
Satz 2.8	Sei \(E\) ein Vektorraum. Ist \(E\) endlichdimensional, so ist jede lineare Abbildung \(A:E \rightarrow F\) beschraenkt und damit stetig.
Satz 2.9	Ist \(f\) in \(x_0\) sowohl stetig als auch differenzierbar, so ist die Ableitung \(f'(x_0)\) eine stetige lineare Abbildung von \(E\) nach \(F\).
Differenzierbar	Die Funktion \(f: \Omega \subseteq E \rightarrow F\) heisst auf der offenen Menge \(\Omega\) differenzierbar, wenn \(f\) in jedem Punkt \(x_0 \in \Omega\) differenzierbar ist.
Stetig Differenzierbar	Die Funktion \(f: \Omega \subseteq E \rightarrow F\) heisst auf der offenen Menge \(\Omega\) stetig differenzierbar, wenn die Abbildung \[f': \Omega \rightarrow L(E,F):x \rightarrow f'(x)\] stetig ist.
Richtungsdifferenzierbar	Die Funktion \(f: \Omega \subseteq E \rightarrow F\) heisst richtungsdifferenzierbar in Richtung \(e \in E, e\neq 0\), wenn die Richtungsableitung existiert.
Richtungsableitung	\[\lim_{t \rightarrow 0} \frac {f(x_0+te)-f(x_0)}{t}\]
Satz 2.13	Ist \(f\) in \(x_0\) differenzierbar, so existieren dort alle Richtungsableitungen und sind gegeben durch \[\lim_{t \rightarrow 0} \frac{f(x_0+te)-f(x_0)}{t} =f'(x_0)e.\]
Partielle Ableitung	Ist \(E=\mathbb{R}^n,F=\mathbb{R}^m\) und \(e=e_i\) der \(i\)-te Einheitsvektor, so ist die Richtungsableitung in Richtung \(e_i\) die partielle Ableitung \[(\frac{\partial f}{\partial x_i})(x)= \lim_{t \rightarrow 0} \frac {f(x+te_1)-f(x)}{t}\] von \(f\) nach der \(i\)-ten Variable im Punkt \(x\).
Aequivalente Schreibweisen fuer partielle Ableitungen	\(D_i f= \frac{\partial f}{\partial x_i} = \frac{\partial}{\partial x_i} f.
Jacobimatrix	Die Jacobimatrix oder Funktionalmatrix von \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m\) ist \[\begin{pmatrix} \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_2}{\partial x_2} \\ \vdots & \ddots & \vdots \\\frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n} \end{pmatrix}\]
Satz 2.18	Ist \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m\) in \(x_0 \in \Omega\) differenzierbar, so ist die Jacobimatrix von \(f\) in \(x_0\) die Darstellung der Ableitung \(f'(x_0)\) bzgl. der Standardbasen des \(\mathbb{R}^n\) und \(\mathbb{R}^m\).
Satz 2.19	Existieren fuer \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m\) die partiellen Ableitungen \(D_i f\) in jedem Punkt aus einer Umgebung \(U \subseteq \Omega\) von \(x_0\) stetig, so ist \(f\) in \(x_0\) differenzierbar.
Gradient	Die Ableitung einer differenzierbaren Funktion \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}\) wird als Gradient von \(f\) bezeichnet und wird als Spaltenvektor \[ \nabla f = (\frac {\partial f}{\partial x_1},\cdots,\frac {\partial f}{\partial x_n})^{T}\] geschrieben.
Satz 2.22	Sei \(g: \Omega \subseteq E \rightarrow F, \Omega \) offen, in \(x_0 \in \Omega\) differenzierbar. Die Funktion \(f: U \subseteq F \rightarrow G\) sei auf einer Umgebung \(U\) von \(g(x_0)\) definiert und in \(g(x_0)\) differenzierbar. Dann ist \(f \circ g: \Omega \rightarrow G: x \mapsto f(g(x))\) in \(x_0\) differenzierbar und \[(f \circ g)'(x_0)=f'(g(x_0)) \circ g'(x_0).\] Bei Interpretation durch Matrizen ist \[(f \circ g)'(x_0)=f'(g(x_0))g'(x_0).\]
Konvex	Eine Menge \(\Omega \subseteq E\) heisst konvex, falls fuer alle \(x, y \in \Omega, \lambda \in [0, 1]\) auch \[\lambda x + (1- \lambda)y\] in \( \Omega\) liegt, \(\Omega\) also zu je zwei Punkten \(x,y \in \Omega\) auch deren Verbindungsstrecke enthaelt.
Satz 2.24	Ist \(\Omega \subseteq \mathbb{R}^n\) konvex, \(f: \Omega \rightarrow \mathbb{R}^m\) (stetig) differenzierbar und liegen \(x\), \(x_0\) in \(\Omega\), so gilt fuer stetig differenzierbare Funktionen \(f\) \[f(x)=f(x_0)+ \int_0^1 f(x_0+t(x-x_0))(x-x_0) \mathrm{d}t = f(x_0)+\int_0^1 \phi '(t) \mathrm{d}t\]
Satz 2.25	Ist \(f'\) Lipschitz-stetig, gibt es also eine Kontante \(L\) mit \[\|f'(x)-f'(y)\|\leq L\|x-y\|\] fuer alle \(x,y \in \Omega \), so ist \[\|f(x)-{f(x_0)+f'(x_0)(x-x_0)}\| \leq \frac{1}{2} L \|x-x_0\|^2.\]
Satz 2.26	Ist \(\Omega \subseteq \mathbb{R}^n\) wegzusammenhaengend, \(f: \Omega \rightarrow \mathbb{R}^m\) differenzierbar und \(f'(x)=0\) fuer alle \(x \in \Omega\), so ist \(f\) konstant.
r-mal stetig differenzierbar	Eine Funktion \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m\) heisst auf der offenen Menge \(\Omega\) r-mal stetig differenzierbar, wenn alle partiellen Ableitungen der Ordnung \(\leq r\) auf ganz \(\Omega\) existieren und stetig von \(x \in \Omega\) abhaengen.
Satz von Schwarz	Fuer zweimal stetig differenzierbare Funktionen \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m\) gilt \[D_iD_jf = D_jD_if.\]





Satz 2.36	Sei \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R},\) zweimal differenzierbar, \(h=(h_1,\cdots,h_n)^T \in \mathbb{R}^n\) und \(x_0+th \in \Omega\) fuer \(0 \leq t \leq 1.\) Dann gibt es ein \( 0 < \vartheta < 1\) mit \[f(x_0 + h) = f(x_0) + \sum \limits_{k=1} \limits^{n} (D_k f)(x_0)h_k + R_1(h)\] mit dem Restglied \[R_1= \frac {1}{2} \sum \limits_{i=1} \limits^{n} \sum \limits_{k=1} \limits^{n} (D_i D_k f)(x_0 + \vartheta h)h_i h_k.\]
Hesse-Matrix	Die \( (n \times n)\)-Matrix \(f''(x)\) mit den Eintraegen \[f''(x)_{ij}=(D_i D_j f)(x)\] heisst Hesse-Matrix der Funktion \(f\) an der Stelle \(x\).
Bemerkung 2.37	Ist \(f''\) stetig, so ist die Hesse-Matrix nach dem Satz von Schwarz Lemma symmetrisch.
Satz 2.38	Sei \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R} (k+1)\)-mal stetig differenzierbar, \(h=(h_1 \cdots h_n)^T \in \mathbb{R}^n\) und \( x_0+th \in \Omega \) fuer \(0 \leq t \leq 1.\) Dann gibt es ein \(0 < \vartheta < 1\) mit \[f(x_0+h)= \sum \limits_{| \alpha | \leq k} \frac{1}{\alpha !} (D^{\alpha}f)(x_0)h^{\alpha}+R_k,\] mit \[R_k= \sum \limits_{|\alpha |=k+1} \frac {1}{\alpha !}(D^{\alpha}f)(x_0+\vartheta h)h^{\alpha}\]
Satz 2.39	Ist \( \Omega \subseteq \mathbb{R}^n\) wegzusammenhaengend, \(f: \Omega \rightarrow \mathbb{R} (k+1)\)-mal stetig differenzierbar und \(D^{\alpha}f = 0\) fuer alle Multiindizes \( \alpha\) mit \(|\alpha |=k+1,\) so ist \( f\) ein Polynom k-ten Grades.
Lokales Minimum	Die Funktion \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R},\) nimmt in \(x_0 \in \Omega\) ein lokaes Minimum an, wenn es eine Umgebung \(U \subseteq \Omega\) von \(x_0\) gibt mit \(f(x) \geq f(x_0)\) fuer alle \(x \in U\).
Lokales Maximum	Die Funktion \(f: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R},\) nimmt in \(x_0 \in \Omega\) ein lokaes Maximum an, wenn es eine Umgebung \(U \subseteq \Omega\) von \(x_0\) gibt mit \(f(x) \leq f(x_0)\) fuer alle \(x \in U\).
Lokales Extremum	Ein lokales Extremum ist ein lokales Minimum oder Maximum.
Isoliertes lokales Extremum	Ein lokales Extremum ist ein lokales Minimum oder Maximum. Tritt Gleichheit der Funktionswerte nur fuer \(x = x_0\) ein, spricht man von einem strikten oder isolierten lokalen Extremum.
Striktes lokales Extremum	Ein lokales Extremum ist ein lokales Minimum oder Maximum. Tritt Gleichheit der Funktionswerte nur fuer \(x = x_0\) ein, spricht man von einem strikten oder isolierten lokalen Extremum.
Satz 2.41	Ist \( \Omega \) offen und nimmt \(f\) in \(x_0 \in \Omega\) ein lokales Extremum an, ist dort \[(\nabla f)(x_0)=0.\]
Positiv definit	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Dann heisst \(S\) positiv definit, falls fuer alle Vektoren \(x \in \mathbb{R}^n, x \neq 0\) \[ \langle x,Sx \rangle > 0\] ist.
Positiv semidefinit	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Dann heisst \(S\) positiv semidefinit, falls fuer alle Vektoren \(x \in \mathbb{R}^n\) \[ \langle x,Sx \rangle > 0 \geq 0\] gilt.
Negativ definit	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Dann heisst \(S\) negativ definit, falls fuer alle Vektoren \(x \in \mathbb{R}^n, x \neq 0\) \[ \langle x,Sx \rangle < 0\] ist.
Negativ semidefinit	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Dann heisst \(S\) negativ semidefinit, falls fuer alle Vektoren \(x \in \mathbb{R}^n\) \[ \langle x,Sx \rangle < 0 \leq 0\] gilt.
Indefinit	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Dann ist \(S\) genau dann indefinit, wenn es echt positive als auch echt negative Eigenwerte gibt.
Bemerkung 2.42	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. \(S\) ist genau dann positiv definit, wenn alle Eigenwerte von \(S\) positiv sind.\\ \(S\) ist genau dann positiv semidefinit, wenn alle Eigenwerte groesser gleich Null sind.\\ \(S\) ist genau dann negativ definit, wenn alle Eigenwerte von \(S\) negativ sind.\\ \(S\) ist genau dann negativ semidefinit, wenn alle Eigenwerte kleiner gleich Null sind.\\ \(S\) ist genau dann indefinit, wenn es sowohl echt positive als auch echt negative Eigenwerte gibt.
Satz 2.43	Sei \(S\) eine symmetrische \((n \times n)\)-Matrix. Ist \(S\) positiv definit, so gibt es ein \(\alpha > 0\) mit \[\langle x,Sx \rangle \geq \alpha \|x\|_{2}^{2}, \quad x \in \mathbb{R}^n.\] Ist \(S\) negativ definit, so gibt es ein \(\alpha > 0\) mit \[\langle x, Sx \rangle \leq -\alpha \|x\|_2^2, \quad x \in \mathbb{R}^n.\] Bemerkung: \(\alpha\) ist der minimale bzw. maximale Eigenwert von \(S\).
Satz 2.44	Sei \(\Omega \subseteq \mathbb{R}^n\) offen, \(f: \Omega \rightarrow \mathbb{R}\) zweimal stetig differenzierbar und es gelte \(\nabla f) (x_0)=0.\) Ist dann \(f''(x_0)\) positiv definit, so nimmt \(f\) in \(x_0\) ein isoliertes lokales Minimum an. \\ Ist \(f''(x_0)\) negativ definit, so nimmt \(f\) in \(x_0\) ein isoliertes lokales Maximum an. \\ Ist \(f''(x_0)\) indefinit, so besitzt \(f\) in \(x_0\) kein lokales Extremum.

Fixpunkt	\(x = \phi (x)\)
Fixpunktiteration	TBD
Vollstaendiger normierter Vektorraum	Ein normierter Vektorraum \(E\) heisst vollstaendig, oder Banachraum, wenn in ihm jede Cauchyfolge konvergiert.
Banachraum	Ein normierter Vektorraum \(E\) heisst vollstaendig, oder Banachraum, wenn in ihm jede Cauchyfolge konvergiert.
Satz 3.2	Der \(\mathbb{R}^n\) ist vollstaendig.
Bemerkung 3.2	Der Raum \(C[a,b]\) versehen mit der Supremumsnorm ist vollstaendig.
Definition 3.3	Sei \(M \subseteq E\). Die Abbildung \(\pho: M \rightarrow E\) heisst Lipschitz-stetig mit der Lipschitz-Konstanten L, wenn fuer alle \(x,y \in M\) \[\|\phi(x)- \phi(y)\| \leq L \|x-y\|\] ist.
Kontraktionssatz	Sei \(M \neq \emptyset\) eine abgeschlossene Teilmenge des Banachraums \(E\) und die Abbildung \(\phi :M \rightarrow M\) sei Lipschitz-stetig mit der Lipschitz-Konstanten \(L < 1.\) Dann besitzt \(\phi\) genau einen Fixpunkt \(x^*=\phi (x^*)\).
Banach\('\)scher Fixpunktsatz	Sei \(M \neq \emptyset\) eine abgeschlossene Teilmenge des Banachraums \(E\) und die Abbildung \(\phi :M \rightarrow M\) sei Lipschitz-stetig mit der Lipschitz-Konstanten \(L < 1.\) Dann besitzt \(\phi\) genau einen Fixpunkt \(x^*=\phi (x^*)\).
Satz 3.5	Sei \(\Omega \subseteq \mathbb{R}^n\) offen und \(f: \Omega \rightarrow \mathbb{R}^n\) stetig differenzierbar. Es sei \(f(x_0)=y_0\) und \(f'(x_0)\) nichtsingulaer. Ist dann fuer alle \(x \in K:= \overline{K(x_0,R)} \subseteq \Omega\) \[\|I-f'(x_0)^{-1}f'(x)\| \leq \vartheta <1,\] so besitzt die Gleichung \(f(x)=y\) fuer alle \(y \in K':=\overline{K(y_0,R')},\) \[R'= \frac{1-\vartheta}{\|f'(x_0)^{-1}\|}R,\] genau eine Loesung \(x \in K\).
Satz 3.6	Es gibt eine auf einer Umgebung \(U\) von \(y_0\) definierte und in \(y_0\) stetige Funktion \(g:U \rightarrow \Omega\) mit \(f(g(y))=y\) fuer alle \(y \in U\).

Lemma 3.8	Die Menge der invertierbaren \((n \times n)\)-Matrizen ist offen. Die Abbildung \(A \mapsto A^{-1}\) dieser Menge in sich ist stetig, sogar lokal Lipschitz-stetig.
