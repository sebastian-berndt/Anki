Adjungierte Abbildung	Ist \(V\) ein endlichdimensionaler euklidischer oder unitaerer Vektorraum mit dem Skalarpprodukt \(\langle \cdot,\cdot \rangle\), so gibt es zu jeder Abbildung \(f \in L(V,V)\) eine eindeutig bestimmte Abbildung \(f^{ad} \in L(V,V)\) fuer die \[\langle f(v),w \rangle = \langle v,f^{ad}(w)\rangle \quad \text{ und } \quad \langle v,f(w) \rangle = \langle f^{ad}(v),w \rangle\] fuer alle \(v,w \in V\) gilt. Dann nennt man die Abbildung \(f^{ad}\) die Adjungierte von \(f\) bzgl. \(\langle \cdot, \cdot \rangle\).
Algebraische Vielfachheit	Sei \(V\) ein endlichdimensionaler \(K\)-Vektorraum, \(f \in f(V,V)\) und sei \(\lambda \in K\) ein Eigenwert von \(f\). Hat das charakteristische Polynom die Form \[P_f = (t-\lambda)^d *g\] fuer ein \(g \in K[t]\) mit \(g(\lambda) \neq 0,\) so nennen wir \(d\) die algebraische Vielfachheit des Eigenwerts \(\lambda\) von \(f\). Wir bezeichnen diese mit \(a(\lambda,f)\).
Assoziativ	Eine zweistellige Verknuepfung \( \ast : A \times A \rightarrow A\) auf einer Menge \(A\) hei\ss t assoziativ, wenn fuer alle \(a,b,c \in A\) das Assoziativgesetz \[a \ast (b \ast c) = (a \ast b) \ast c\] gilt.
Au\ss ere Verknuepfung	Seien \(A_1,\ldots,A_n\) und \(B\) Mengen. Ist dann \(*\) eine \(n\)-stellige Verknuepfung mit \[*: A_1,\ldots,A_n \rightarrow B\] mit \(A_i \neq B\) fuer \(1 \leq i \leq m\) und \(A_i = B\) fuer \(m+1 \leq i \leq n\) fuer ein \(M\) mit \(0 \leq m < n\), so nennt man \(*\) aeu\ss ere \(n\)-stellige Verknuepfung.
Automorphmismus	Ein bijektiver Endomorphismus hei\ss t Automorphismus.
Basis eines Vektorraums	Sei \(V\) ein \(K\)-Vektorraum. Eine Menge \(\{v_1,\ldots,v_n\} \subseteq V\) hei\ss t Basis von \(V\), wenn gilt: \begin{enumerate} \item \(v_1,\ldots,v_n\) sind linear unabhaengig. \item \(v_1,\ldots,v_n\) erzeugen den Vektorraum \(V\), (d.h. \(\text{Span} \{v_1,\cdots, v_n\}=V\))\end{enumerate}
Bild	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\), dann hei\ss t: \[Bild(f):=\{f(v)|v \in V\} \subseteq W.\]
Bilinearform	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume. Eine Abbildung \(\beta : V \times W \rightarrow K\) hei\ss t Bilinearform auf \(V \times W\), wenn \begin{enumerate} \item \(\beta (v_1 + v_2,w) = \beta (v_1,w) + \beta(v_2,w),\) \item \(\beta (v,w_1 +w_2)= \beta (v,w_1)+ \beta (v,w_2),\) \item \(\beta (\lambda v,w)=\beta (v, \lambda w)= \lambda \beta(v,w),\) \end{enumerate} fuer alle \(v,v_1,v_2 \in V, w,w_1,w_2 \in W\) und \(\lambda \in K\) gilt.
Charakteristisches Polynom	Sind \(n \in \mathbb{N}, V\) ein \(n\)-dimensionaler \(K\)-Vektorraum mit Basis \(B\) und \(f \in L(V,V),\) dann nennen wir \[P_f := \det(t I_n -[f]_{B,B}) \in K[t]\] das charakteristische Polynom von \(f\).
Darstellende Matrix einer Bilinearform	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume mit Basen \(B_1=\{v_1,\ldots,v_m\}\) und \(B_2=\{w_1,\ldots,w_n\}\). Ist \(\beta\) eine Bilinearform auf \(V \times W\), so hei\ss t \[[\beta]_{B_1 \times B_2}=[b_{ij}] \in K^{n,m}, \quad b_{ij}:=\beta (v_j,w_i),\] die Matrixdarstellung oder darstellende Matrix von \(\beta\) bzgl. der Basen \(B_1\) und \(B_2\).
Darstellende Matrix einer Sesquilinearform	Seien \(V\) und \(W\) zwei \(\mathbb{C}\)-Vektorraeume mit Basen \(B_1 = \{v_1,\ldots,v_m\}\) und \(B_2=\{w_1,\ldots,w_n\}\). Ist \(s\) eine Sesquilinearform auf \(V \times W\), so hei\ss t \[[s]_{B_1 \times B_2}=[b_{ij}] \in \mathbb{C}^{n,m}, \quad b_{ij}:=s(v_j,w_i),\] die Matrixdarstellung oder die darstellende Matrix von \(s\) bzgl. der Basen \(B_1\) und \(B_2\).
Darstellende Matrix eines Homomorphismus	Die durch \[(f(v_1),\ldots,f(v_m)) = (w_1,\ldots,w_n)A\] eindeutig bestimmte Matrix hei\ss t die Matrixdarstellung oder darstellende Matrix von \(f \in L(V,W)\) bzgl. der Basen \(B_1=\{v_1,\ldots,v_m\}\) von \(V\) und \(B_2=\{w_1,\ldots,w_n\}\) von \(W\). Wir bezeichnen diese Matrix mit \([f]_{B_1,B_2}\).
Definitheit	Eine reelle symmetrische oder komplex hermitesche \((n \times n)\)-Matrix \(A\) hei\ss t \begin{description} \item[positiv semidefinit,]wenn \(v^HAv \geq 0\) fuer alle \(v \in \mathbb{R}^{n,1}\) bzw. \(v \in \mathbb{C}^{n,1}\) gilt, \item[positiv definit,]wenn \(v^HAv > 0\) fuer alle \(v \in \mathbb{R}^{n,1} \setminus \{0\}\) bzw. \(v \in \mathbb{C}^{n,1}\setminus \{0\}\) gilt, \item[negativ semidefinit,]wenn \(v^HAv \leq 0\) fuer alle \(v \in \mathbb{R}^{n,1}\) bzw. \(v \in \mathbb{C}^{n,1}\) gilt, \item[negativ definit,]wenn \(v^HAv < 0\) fuer alle \(v \in \mathbb{R}^{n,1} \setminus \{0\}\) bzw. \(v \in \mathbb{C}^{n,1}\setminus \{0\}\) gilt. \end{description}
Diagonalisierbar	Sei \(V\) ein endlichdimensionaler \(K\)-Vektorraum. Ein Endomorphismus \(f \in L(V,V)\) hei\ss t diagonalisierbar, wenn es eine Basis \(B\) von \(V\) gibt, so dass \([f]_{B,B}\) eine Diagonalmatrix ist.
Duale Abbildung	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume mit ihren jeweiligen Dualraeumen \(V^*,W^*\) und sei \(f \in L(V,W)\). Dann hei\ss t \[f^*:W^* \rightarrow V^*, \quad h \mapsto h \circ f,\] also \(f^*(h)=h \circ f\) fuer alle \(h \in W^*\), die zu \(f\) duale Abbildung.
Duale Basis	Sei \(V\) ein \(n\)-dimensionaler \(K\)-Vektorraum mit einer gegebenen Basis \(B = \{v_1,\ldots,v_n\}\). Dann gibt es genau eine Basis \(B^*=\{v_1^*,\ldots,v_n^*\}\) von \(V^*\) mit der Eigenschaft: \[v_j^*(v_j)=\delta_{ij}, \quad i,j=1,\ldots,n.\] Wir nennen \(B^*\) die zu \(B\) duale Basis \(V^*\).
Duales Raumpaar	Ist \(\beta\) eine nicht ausgeartete Bilinearform auf \(V \times W\), so nennen wir die Raeume \(V,W\) ein duales Paar von Raeumen oder duales Raumpaar von \(\beta\).
Dualraum	Ist \(V\) ein \(K\)-Vektorraum. Den \(K\)-Vektorraum \(V^*:=L(V,K)\) nennen wir den Dualraum von \(V\).
Eigenraum	Sind \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\), so hei\ss t der Unterraum \[V_f(\lambda):= Kern(\lambda Id_V - f)\] der Eigenraum von \(f\) zum Eigenwert \(\lambda\).
Eigenvektor	Sei \(V\) ein \(K\)-Vektorraum und sei \(f \in L(V,V).\) Falls fuer ein \(v \in V \setminus \{0\}\)  und ein \(\lambda \in K\) die Gleichung \[f(v)=\lambda v\] gilt, so nennt man \(\lambda\) einen Eigenwert von \(f\) und \(v\) einen zum Eigenwert \(\lambda\) gehoerenden Eigenvektor von \(f\).
Eigenwert	Sei \(V\) ein \(K\)-Vektorraum und sei \(f \in L(V,V).\) Falls fuer ein \(v \in V \setminus \{0\}\)  und ein \(\lambda \in K\) die Gleichung \[f(v)=\lambda v\] gilt, so nennt man \(\lambda\) einen Eigenwert von \(f\) und \(v\) einen zum Eigenwert \(\lambda\) gehoerenden Eigenvektor von \(f\).
Einselement	Sei \((R,\oplus, \otimes)\) ein Ring. Ein Element \(1 \in R\) hei\ss t Einselement (kurz Eins), falls die Halbgruppe \((R,\otimes)\) ein Monoid ist, also ein neutrales Element 1 besitzt.
Endomorphismus	Eine Abbildung \(f \in L(V,V)\) hei\ss t Endomorphismus.
Euklidische Norm des \(\mathbb{C}^{n,1}\)	Ist \(\langle \cdot,\cdot \rangle\) das Standardskalarprodukt des \(\mathbb{C}^{n,1}\), dann ist durch \[\|v\|:=\langle v,v \rangle ^{1/2}=(v^Hv)^{1/2}\] eine Norm definiert, die man die euklidische Norm des \(\mathbb{C}^{n,1}\) nennt.
Euklidische Norm des \(\mathbb{R}^{n,1}\)	Ist \(\langle \cdot,\cdot \rangle\) das Standardskalarprodukt des \(\mathbb{R}^{n,1}\), dann ist durch \[\|v\|:=\langle v,v \rangle ^{1/2}=(v^Tv)^{1/2}\] eine Norm definiert, die man die euklidische Norm des \(\mathbb{R}^{n,1}\) nennt.
Euklidischer Vektorraum	Ein \(\mathbb{R}\)-Vektorraum mit einem Skalarprodukt hei\ss t euklidischer Vektorraum.
Geometrische Vielfachheit	Sind \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\), so hei\ss t \[g(\lambda, f):=dim(V_f(\lambda)\] die geometrische Vielfachheit des Eigenwertes \(\lambda\) von \(f\).
Gruppe	Eine Gruppe ist eine Algebraische Struktur bestehend aus einer Menge \(G\) mit einer inneren zweistelligen Verknuepfung fuer die gilt: \begin{enumerate} \item Die Verknuepfung ist assoziativ \item Es gibt ein neutrales Element \(e \in G\) \item Zu jedem \(a \in G\) gibt es ein inverses Element \end{enumerate}
Gruppeneigenschaften	Fuer jede Gruppe \((G,\oplus)\) gilt: \begin{enumerate} \item Ist \(e \in G\) ein neutrales Element und sind \(a,\tilde{a} \in G\) mit \( \tilde{a} \oplus a = e\), so gilt auch \(a \oplus \tilde{a} = e\). \item Ist \(e \in G\) ein linksneutrales Element und ist \(a \in G\), so gilt auch \[a \oplus e = a.\] \item \(G\) enthaelt genau ein neutrales Element. \item Zu jedem \(a \in G\) gibt es genau ein inverses Element. \end{enumerate}
Gruppenhomomorphismus	Seien \((G_1, \oplus)\) und \((G_2, \otimes)\) Gruppen. Eine Abbildung \[ \varphi : G_1 \rightarrow G_2, g \mapsto \varphi (g),\] hei\ss t Gruppenhomomorphismus, wenn \[\varphi(a \oplus b) = \varphi (a) \otimes \varphi (b), \forall a,b \in G_1\] gilt.
Gruppenisomorphismus	Ein bijektiver Gruppenhomomorphismus wird Gruppenisomorphismus genannt.
Halbgruppe	Ein assoziatives Magma hei\ss t Halbgruppe.
Hermitesche Matrix	Ist \(A= [a_{ij}] \in \mathbb{C}^{n,m},\) so ist die hermitesch Transponierte von \(A\) die Matrix \[A^H:=[\bar{a}_{ij}]^T \in \mathbb{C}^{m,n}.\] Ist \(A=A^H\), so nennen wir \(A\) eine hermitesche Matrix.
Hermitesche Sesquilinearform	Eine Sesquilinearform \(s\) auf \(V\) hei\ss t hermitesch, wenn \(s(v,w)=\overline{s(w,v)}\) fuer alle \(v, w \in V\) gilt.
Homomorphismus	Eine lineare Abbildung \(f: W \rightarrow V\) wird Homomorphismus genannt.
Innere Verknuepfung	Seien \(A_1,\ldots,A_n\) und \(B\) Mengen. Ist dann \(*\) eine \(n\)-stellige Verknuepfung mit \[*: A_1,\ldots,A_n \rightarrow B\] mit \(A_i = B\) fuer alle \(1 \leq i \leq n\), so nennt man \(*\) innere \(n\)-stellige Verknuepfung.
Inverses Element	Sei \((S,\ast)\) ein Magma und \(e\) ein neutrales Element von \((S,\ast)\). Dann hei\ss t ein Element \(a \in S\) \begin{description} \item[Linksinverse von b] falls \(a \ast b = e\) fuer \(b \in S\) ist, \item[Rechtsinverse von b] falls \(b \ast a = e\) fuer \(b \in S\) ist, \item[Inverse von b] falls \(a\) sowohl die Linksinverse als auch die Rechtsinverse von b ist. \end{description}
Irreduzibel/Reduzibel	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Ein nicht-konstantes Polynom \(p \in K[t]\) hei\ss t irreduzibel (ueber \(K\)), wenn aus \(p=s*q\) fuer zwei Polynome \(s,q \in K[t]\) folgt, dass \(s\) oder \(q\) ein konstantes Polynom ist. Falls es zwei nicht-konstante Polynome \(s,q \in K[t]\) mit \(p=s*q\) gibt, so hei\ss t \(p\) reduzibel (ueber K)
Isomorphmismus	Ein bijektiver Homomorphismus hei\ss t Isomorphismus.
Kern	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\), dann hei\ss t: \[Kern(f):=\{v \in V|f(v)=0\}.\]
Koerper	Ein Koerper ist eine Algebraische Struktur bestehend aus einer Menge \(K\) mit zwei inneren zweistelligen Verknuepfungen \(\oplus\) und \(\otimes\) fuer die folgende Regeln erfuellt sind: \begin{enumerate} \item \((K,\oplus)\) ist eine kommutative Gruppe. (Dabei hei\ss t das neutrale Element bzgl \(\oplus\) Null und wird mit \(0\) bezeichnet. Das zu \(a \in K\) inverse Element bezeichnet man mit \(-a\).) \item \((K \setminus \{0\},\otimes)\) ist eine kommutative Gruppe. (Man nennt das neutrale Element bzgl. \(\otimes\) Eins und bezeichnet es mit \(1\). Das zu \(a \in K \setminus \{0\}\) inverse Element bezeichnet man mit \(a^{-1}\)) \item Es gelten die Distributivgesetze, sodass fuer alle \(a,b,c \in K\) gilt: \[a \otimes (b \oplus c) = a \otimes b \oplus a \otimes c,\] \[(a \oplus b) \otimes c = a \otimes c \oplus b \otimes c.\] \end{enumerate}
Koerpereigenschaften	Fuer jeden Koerper \(K\) gelten folgende Aussagen: \begin{enumerate} \item \(K\) hat mindestens zwei Elemente. \item \(0 \otimes a = a \otimes 0 = 0\) fuer alle \(a \in K.\) \item \(a \otimes b = a \otimes c\) und \(a \neq 0\) impliziert \(b = c\) fuer alle, \(a,b,c \in K.\) \item \(a \otimes b = 0\) impliziert \( a = 0\) oder \(b=0\), fuer alle \(a,b \in K.\)\end{enumerate}
Kommutative Gruppe	Eine Gruppe \((G,\oplus)\) hei\ss t kommutativ oder abelsch, falls fuer alle \(a,b \in G\) das Kommutativgesetz gilt: \[ a \oplus b = b \oplus a.\]
Kommutativer Ring	Ein Ring \((R,\oplus, \otimes)\) hei\ss t kommutativ falls fuer alle \(a,b \in R\) mit \(\otimes\) das Kommutativgesetz gilt: \[a \otimes b = b \otimes a\]
Kongruente Matrizen	Falls fuer zwei Matrizen \(A,B \in K^{n,n}\) eine Matrix \(Z \in GL_n(K)\) mit \(B=Z^T AZ\) existiert, so hei\ss en \(A\) und \(B\) kongruent.
Koordinatenabbildung	Ist \(B=\{v_1,\ldots,v_n\}\) eine Basis des \(K\)-Vektorraums \(V\), so ist die Abbildung \[\phi_B:V \rightarrow K^{n,1}, v=\lambda_1 v_1 + \ldots + \lambda_n v_n \mapsto \phi_B(v):=\begin{bmatrix}\lambda_1\\\vdots\\\lambda_n\end{bmatrix},\] ein Isomorphismus, den wir die Koordinatenabbildung von \(V\) bzgl. der Basis \(B\) nennen.
Lineare Abbildung	Seien \(V\) und \(W\) zwei \(K\)-Vektorraeume. Eine Abbildung \(f: V \rightarrow W\) hei\ss t \(K\)-linear (kurz: linear), wenn fuer alle \(v,w \in V\) und \(\lambda \in K\) die Gleichungen \begin{enumerate} \item \(f(\lambda v)=\lambda f(v)\), \item \(f(v+w) = f(v) + f(w)\), \end{enumerate} gelten. Die Menge aller dieser Abbildungen bezeichnen wir mit \(L(V,W)\).
Lineare Unabhaengigkeit	Sei \(V\) ein \(K\)-Vektorraum. Die Vektoren \(v_1,\cdots,v_n \in V\) hei\ss en linear unabhaengig, wenn aus \(\sum_{i=1}^n \lambda_i v_i =0\) mit \(\lambda_1,\cdots,\lambda_n \in K\) folgt, dass \(\lambda_1,\cdots,\lambda_n \in K,\) die nicht alle gleich Null sind, so hei\ss en \(v_1,\cdots,v_n\) linear abhaengig.
Linearform	Ist \(V\) ein \(K\)-Vektorraum, so nennen wir eine Abbildung \(f \in L(V,K)\) eine Linearform auf \(V\).
Magma/Gruppoid	Ein Magma (oder auch Gruppoid) ist eine Algebraische Struktur \((M,*)\) bestehend aus einer Menge \(M\) und einer inneren, zweistelligen Verknuepfung \[*:M \times M \rightarrow M.\]
Matrix-Multiplikation	Sei \((R,+,\cdot)\) ein kommutativer Ring mit Eins. Die Multiplikation zweier Matrizen ist definiert als: \[*:R^{n,m} \times R^{m,s} \rightarrow R^{n,s}, \quad (A,B) \mapsto A*B=[c_{ij}], \quad c_{ij}:=\sum_{k=1}^m a_{ik}b_{bj}.\]
Monoid	Ein Monoid ist ein Halbgruppe mit neutralem Element.
Neutrales Element	Sei \((S,\ast)\) ein Magma. Dann hei\ss t ein Element \(e \in S\) \begin{description} \item[linksneutral], falls \(e \ast a = a\) fuer alle \(a \in S\) ist, \item[rechtsneutral], falls \(a \ast e = a\) fuer alle \(a \in S\) ist, \item[neutral], falls \(e\) linksneutral und rechtsneutral ist. \end{description}
Nicht ausgeartet in der ersten Variablen	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartet in der ersten Variablen, wenn aus \(\beta(v,w)=0\) fuer alle \(w \in W\) folgt, dass \(v=0\) ist.
Nicht ausgeartet in der zweiten Variablen	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartet in der zweiten Variablen, wenn aus \(\beta(v,w)=0\) fuer alle \(v \in W\) folgt, dass \(w=0\) ist.
Nicht ausgeartete Bilinearform	Eine Bilinearform \(\beta\) auf \(V \times W\) hei\ss t nicht ausgeartete Bilinearform, falls \(\beta\) in beiden Variablen nicht ausgeartet ist.
Norm	Sei \(V\) ein \(\mathbb{K}\)-Vektorraum. Eine Abbildung \(\|\cdot\|:V \rightarrow \mathbb{R}\) hei\ss t Norm auf \(V\), falls fuer alle \(v,w \in V\) und alle \(\lambda \in \mathbb{K}\) gilt: \begin{enumerate} \item \(\|v\| \geq 0\) und \(\|v\|=0 \Leftrightarrow v = 0\). \item \(\|\lambda v \| = |\lambda| \cdot \|v\|\) (absolute Homogenitaet) \item \(\|v+w\| \leq \|v\|+\|w\| (Dreiecksungleichung)\end{enumerate}
Normale Matrix	 Eine Matrix \(A \in \mathbb{R}^{n,n}\) oder \(A \in \mathbb{C}^{n,n}\) hei\ss t normal, wenn \(A^TA =AA^T\) bzw. \(A^HA=AA^H\) gilt.
Normaler Endomorphismus	Sei \(V\) ein endlichdimensionaler euklidischer oder unitaerer Vektorraum. Ein Endomorphismus \(f \in L(V,V)\) hei\ss t normal, wenn \(f \circ f^{ad}=f^{ad} \circ f\) gilt.
Normierter Raum	Ein \(\mathbb{K}\)-Vektorraum, auf dem eine Norm definiert ist, hei\ss t normierter Raum.
Nullteiler	Sei \((R,\oplus,\otimes)\) ein Ring. Dann hei\ss t \(a \in R\) ein Nullteiler, wenn ein \( b \in R \setminus \{0\}\) mit \(a \otimes b = 0\) existiert.
Orthogonalbasis	Eine Basis \(\{v_1,\cdots,v_j\}\) hei\ss t Orthogonalbasis, wenn \[\langle v_i,v_j \rangle =0, \quad i,j=1,\cdots,n \text{ und } i \neq j,\] gilt.
Orthogonale Matrix	Eine Matrix \(Q \in \mathbb{R}^{n,n}\), deren Spalten eine Orthonormalbasis bzgl. des Standardskalarprodukts des \(\mathbb{R}^{n,1}\) bilden, hei\ss t orthogonale Matrix.
Orthogonale Vektoren	Sei \(V\) ein euklidischer oder ein unitaerer Vektorraum mit dem Skalarprodukt \(\langle \cdot,\cdot \rangle\). Zwei Vektoren \(v,w \in V\) hei\ss en orthogonal bzgl. des gegebenen Skalarprodukts \(\langle \cdot,\cdot \rangle\), wenn \(\langle v,w \rangle =0\) gilt.
Orthogonales Komplement	Sei \(V\) ein euklidischer oder ein unitaerer Vektorraum mit dem Skalarprodukt \(\langle \cdot, \cdot \rangle\) und sei \(U \subseteq V\) ein Unterraum. Dann hei\ss t \[U^{\bot}:=\{v \in V|\langle v,u \rangle =0 \text{ fuer alle } u \in U\}\] das orthogonale Komplement von \(U\) (in \(V\)).
Orthonormalbasis	Eine Basis \(\{v_1,\cdots,v_j\}\) hei\ss t Orthonormalbasis, wenn \[\langle v_i,v_j \rangle =0, \quad i,j=1,\cdots,n \text{ und } i \neq j,\] gilt, sowie \[\|v_i\|=1, \quad i=1,\cdots,n,\] wobei \(\|v\|=\langle v,v \rangle ^{1/2}\) die vom Skalarprodukt induzierte Norm ist, so hei\ss t \(\{v_1,\cdots,v_j\}\) Orthogonalbasis von \(V\). Fuer eine Orthonormalbasis gilt also \(\langle v_i,v_j\rangle = \delta _{ij}.\)
Rechenregeln fuer die Matrizenmultiplikation	Fuer \(A,\hat{A} \in R^{n,m}, B, \hat{B} \in R^{m,l}\) und \(C \in R^{l,k}\) gelten: \begin{description} \item[Assoziativitaet] \(A*(B*C)=(A*B)*C\) \item[rechtsdistributiv] \((A+\hat{A})*B=A*B+\hat{A}*B\) \item[linksdistributiv] \(A*(B+\hat{B})=A*B+A*\hat{B}\) \item[to-be-named] \(I_n*A=A*I_m=A\) \end{description}
Rechenregeln fuer die skalare Matrix-Multiplikation	Fuer \(A,\hat{A} \in R^{n,m}, B, \hat{B} \in R^{m,l}\) und \(C \in R^{l,k}\) gelten: \begin{description} \item[Assoziativitaet] \((\lambda \mu)\cdot A=\lambda \cdot (\mu \cdot A)\) \item[rechtsdistributiv] \((\lambda +\mu)\cdot A = \lambda \cdot A + \mu \cdot A\) \item[linksdistributiv] \(\lambda \cdot (A+B)=\lambda \cdot A+\lambda \cdot B\) \item[to-be-named] \((\lambda \cdot A) *C=\lambda \cdot(A*C)=A*(\lambda \cdot C)\) \end{description}
Ring	Ein Ring ist eine eine Algebraische Struktur bestehend aus einer Menge \(R\) mit zwei zweistelligen Verknuepfungen \( \oplus, \otimes\) fuer die gilt: \begin{enumerate} \item \((R,\oplus)\) ist eine kommutative Gruppe \item \((R,\otimes)\) ist eine Halbgruppe \item Fuer alle \(a,b,c \in R\) gelten die Distributivgesetze mit: \[a \otimes (b \oplus c) = a \otimes b \oplus a \otimes c\] \[(a \oplus b) \otimes c = a \otimes c \oplus b \otimes c\]  \end{enumerate}
Ring mit Eins	Sei \((R,\oplus, \otimes)\) ein Ring. Ist die Halbgruppe \((R,\otimes)\) ein Monoid, besitzt also ein Einselement, dann nennt man \((R, \oplus, \otimes)\) einen Ring mit Eins.
Ringeigenschaften	Sei \((R,\oplus, \otimes)\) ein Ring. Dann gilt: \begin{enumerate} \item \(0 \otimes a = a \otimes 0 = 0\) fuer alle \(a \in R\) \item \(a \otimes (-b) = -(a \otimes b) = (-a) \otimes b\) und \((-a) \otimes (-b) = a \otimes b\)  fuer alle \(a,b \in R\)\end{enumerate}
Satz 3.11	Sei \((R,\oplus,\otimes)\) ein Ring mit Eins. Dann gilt: \begin{enumerate} \item Falls zu \(a \in R\) ein inverses Element (bezueglich \(\otimes\)) existiert, so ist dieses eindeutig. Man bezeichnet es dann mit \(a^{-1}\). \item Sind \(a,b \in R\) invertierbar, so ist \(a \otimes b\) invertierbar und \[(a \otimes b)^{-1}=b^{-1} \otimes a^{-1}.\]\end{enumerate}
Schur-Form einer Matrix	Ist \(A \in \mathbb{C}^{n,n}\), so gibt es eine unitaere Matrix \(Q \in C^{n,n}\) und eine obere Dreiecksmatrix \(R \in \mathbb{C}^{n,n}\) mit \(A=QRQ^H\). Die Matrix \(R\) nennen wir eine Schur-Form von \(A\).
Selbstadjungierte Endomorphismus	Sei \(V\) ein endlichdimensionaler euklidischer oder unitÃ¤rer Vektorraum. Eine Abbildung \(f \in L(V,V)\) hei\ss t selbstadjungiert, wenn gilt: \[f = f^{ad}\]
Sesquilinearform	Seien \(V\) und \(W\) zwei \(\mathbb{C}\)-Vektorraeume. Eine Abbildung \(s: V \times W \rightarrow \mathbb{C}\) hei\ss t Sesquilinearform auf \(V \times W\), wenn \begin{enumerate} \item \(s(v_1 +v_2,w)=s(v_1,w)+s(v_2,w),\) \item \(s(\lambda v,w) = \lambda s(v,w),\) \item \(s(v,w_1+w_2)=s(v,w_1)+s(v,w_2),\) \item \(s(v,\lambda w)=\bar{\lambda} s(v,w),\) \end{enumerate} fuer alle \(v,v_1,v_2 \in V, w,w_1,w_2 \in W\) und \(\lambda \in \mathbb{C}\) gilt.
Skalare Matrix-Multiplikation	Sei \((R,+,\cdot)\) ein kommutativer Ring mit Eins. Die Multiplikation eines Skalars und einer Matrix ist definiert als: \[\cdot: R \times R^{n,m} \rightarrow R^{n,m}, \quad (\lambda, A) \mapsto \lambda \cdot A:=[\lambda a_{ij}].\]
Skalarprodukt/inneres Produkt	Sei \(V\) ein \(K\)-Vektorraum, wobei entweder \(K=\mathbb{R}\) oder \(K=\mathbb{C}\) gelten soll. Eine Abbildung \[\langle \cdot,\cdot \rangle:V \times V \rightarrow K, \quad (v,w) \mapsto \langle v,w \rangle,\] hei\ss t Skalarprodukt oder inneres Produkt auf \(V\), wenn gilt: \begin{enumerate} \item Ist \(K = \mathbb{R}\), so ist \(\langle \cdot,\cdot \rangle\) eine symmetrische Bilinearform. Ist \(K=\mathbb{C}\), so ist \(\langle \cdot,\cdot \rangle\) eine hermitische Sesquilinearform. \item \(\langle \cdot,\cdot \rangle\) ist positiv definit, d.h. es gilt \(\langle v,v \rangle \geq 0\) fuer alle \(v \in V\) mit Gleichheit genau dann, wenn \(v=0\) ist.\end{enumerate}
Standardskalarprodukt des \(\mathbb{C}^{n,1}\)	Auf dem Vektorraum \(\mathbb{C}^{n,1}\) ist \[\langle v,w \rangle := w^Hv\] ein Skalarprodukt, welches das Standardskalarprodukt des \(\mathbb{C}^{n,1}\) genannt wird.
Standardskalarprodukt des \(\mathbb{R}^{n,1}\)	Auf dem Vektorraum \(\mathbb{R}^{n,1}\) ist \[\langle v,w \rangle := w^Tv\] ein Skalarprodukt, welches das Standardskalarprodukt des \(\mathbb{R}^{n,1}\) genannt wird.
Symmetrische Bilinearform	Eine Bilinearform \(\beta\) auf \(V\) hei\ss t symmetrisch, wenn \(\beta (v,w)= \beta (w,v)\) fuer alle \(v,w \in V\) gilt.
Teiler	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Wenn es fuer zwei Polynome \(p,s \in K[t]\) ein Polynom \(q \in K[t]\) mit \(p=s*q\) gibt, dann hei\ss t \(s\) ein Teiler von \(p\) und wir schreiben \(s|p\) (s teilt p).
Teilerfremde Polynome	Sei \(K\) ein Koerper und \(K[t]\) der Ring der Polynome ueber \(K\). Zwei Polynome \(p,s \in K[t]\) hei\ss en teilerfremd, wenn aus \(q|p\) und \(q|s\) fuer ein \(q \in K[t]\) stets folgt, dass \(q\) ein kostantes Polynom ist.
Teilkoerper	Sei \((K, \oplus, \otimes)\) ein Koerper und \(L \subseteq K\). Ist \((L, \oplus, \otimes)\) ein Koerper, so nennen wir diesen einen Teilkoerper von \((K,\oplus,\otimes).\)
Teilkorperkriterium	Sei \((K,+,*)\) ein Koerper. Dann ist \((L,+,*)\) genau dann ein Teilkoerper von \((K,+,*)\), wenn gilt: \begin{enumerate} \item \(L \subseteq K,\) \item \(0_K, 1_K \in L,\) \item \(a + b \in L\) und \(a * b \in L\) fuer alle \(a,b \in L,\) \item \(-a \in L\) fuer alle \(a \in L,\) \item \(a^{-1} \in L\) fuer alle \(a \in L \setminus \{0\}.\) \end{enumerate}
Traegheitsindex einer Matrix	Ist \(A \in \mathbb{R}^{n,n}\) symmetrisch oder \(A \in \mathbb{C}^{n,n}\) hermitesch mit \(n_+\) positiven, \(n_-\) negativen und \(n_0\) Null Eigenwerten, dann hei\ss t der Tripel \((n_+,n_-,n_0)\) der Traegheitsindex von \(A\).
Unitaere Matrix	Eine Matrix \(Q \in \mathbb{C}^{n,n}\), deren Spalten eine Orthonormalbasis bzgl. des Standardskalarprodukts des \(\mathbb{C}^{n,1}\) bilden, hei\ss t unitaere Matrix.
Unitaerer Vektorraum	Ein \(\mathbb{C}\)-Vektorraum mit einem Skalarprodukt hei\ss t unitaerer Vektorraum.
Untergruppe	Sei \((G,\oplus)\) eine Gruppe und \(H \subseteq G\). Ist \((H,\oplus)\) eine Gruppe, so nennt man \((H, \oplus)\) eine Untergruppe von \((G,\oplus)\).
Untergruppenkriterium	\((H, \oplus)\) ist genau dann eine Untergruppe der Gruppe \((G,\oplus)\), wenn Folgendes gilt: \begin{enumerate} \item \(\emptyset \neq H \subseteq G.\) \item \(a \oplus b \in H\) fuer alle \(a,b \in H.\) \item Fuer jedes \(a \in H\) ist sein inverses Element \(\tilde{a} \in H.\)  \end{enumerate}
Unterraum	Sei \((V,+,\cdot)\) ein \(K\)-Vektorraum und sei \(U \subseteq V.\) Ist \((U,+,\cdot)\) ein \(K\)-Vektorraum, so nennt man diesen einen Unterraum von \((V,+,\cdot)\).
Unterringkriterium	Sei \((R,+,*)\) ein Ring. Eine Teilmenge \(S \subseteq R\) hei\ss t Unterring von \(R\), wenn \((S,+,*)\) ein Ring ist. Dann ist \(S\) genau dann ein Unterring von \(R\), wenn gilt: \begin{enumerate} \item \(S \subseteq R,\) \item \(0_R \in S,\) \item Fuer alle \(r,s \in S\) sind \(r+s \in S\) und \(r*s \in S\), \item Fuer jedes \(r \in S\) ist \(-r \in S\). \end{enumerate}
Untervektorraumkriterium	Sei \((U,+,\cdot)\) ist genau dann ein Unterraum von \((V,+,\cdot)\), wenn folgende Eigenschaften gelten: \begin{enumerate} \item \(U \neq \emptyset\) \item \(v+w \in U\) fuer alle \(v,w \in U\) \item \(\lambda v \in U\) fuer alle \(\lambda \in K\) und \(v \in U\) \end{enumerate}
Urbild	Sind \(V\) und \(W\) zwei \(K\)-Vektorraeume und \(f \in L(V,W)\). Dann definiert man das Urbild von \(w\) in \(V\) als \[f^{-1}(w):=f^{-1}({w})=\{w \in V|f(v)=w\}.\]
Vektorprodukt/Kreuzprodukt	Das Vektorprodukt oder Kreuzprodukt im \(\mathbb{R}^{3,1}\) ist die Abbildung \[\mathbb{R}^{3,1} \times \mathbb{R}^{3,1} \rightarrow \mathbb{R}^{3,1} , \quad (v,w) \mapsto v \times w,\] mit \(v \times w := [v_2w_3-v_3w_2, v_3w_1-v_1w_3, v_1w_2-v_2w_1]^T\) fuer \(v=[v_1,v_2,v_2]^T, w=[w_1,w_2,w_3]^T \in \mathbb{R}^{3,1}\).
Vektorraum	Sei \(K\) ein Koerper. Ein Vektorraum ueber \(K\) (kurz: \(K\)-Vektorraum) ist eine Menge \(V\) mit zwei Abbildungen, \begin{description} \item[(Addition)] \(+:V \times V \rightarrow V, \quad (v,w) \mapsto v+w,\) \item[(Skalare Multiplikation)] \(\cdot :K \times V \rightarrow V, \quad (\lambda,v) \mapsto \lambda \cdot v,\)\end{description} fuer die folgende Regeln erfuellt sind: \begin{enumerate} \item \((V,+)\) ist eine kommutative Gruppe. \item Fuer alle \(v,w \in V\) und \(\lambda, \mu \in K\) gelten: \begin{enumerate} \item \(\lambda \cdot (\mu \cdot v)=(\lambda \mu) \cdot v.\) \item \(1 \cdot v = v\) \item \(\lambda \cdot (v+w)=\lambda \cdot v + \lambda \cdot w.\) \item \((\lambda + \mu) \cdot v = \lambda \cdot v + \mu \cdot v.\) \end{enumerate}\end{enumerate}
Verknuepfung	Fuer eine natuerliche Zahl \(n \in \mathbb{N}\) seien \(n\) Mengen \( A_1, \cdots, A_n\) und eine weitere Menge \(B\) gegeben. Dann bezeichnet man eine Abbildung \( \ast\) des kartesischen Produkts \(A_1 \times \cdots \times A_n\) nach \(B\) als \(n\)-stellige Verknuepfung. \[ \ast : A_1 \times \cdots \times A_n \rightarrow B, (a_1,\ldots,a_n) \mapsto \ast (a_1, \ldots, a_n)\] Anstatt \(\ast (a_1, \ldots, a_n)\) schreibt man meistens \( a_1 \ast \ldots \ast a_n\)
Vielfachheit	Seien \(p \in K[t]\) und \(\lambda \in K\) eine Nullstelle von \(p\). Dann ist die Vielfachheit der Nullstelle \(\lambda\) die eindeutig bestimmte natuerliche Zahl \(m\), so dass \(p=(t-\lambda )^m*q\) fuer ein Polynom \(q \in K[t]\) mit \(q(\lambda) \neq 0\) ist.
\(f\)-invarianter Unterraum	Sei \(V\) ein \(K\)-Vektorraum und \(\lambda \in K\) ein Eigenwert von \(f \in L(V,V)\) und \(U \subseteq V\) ein Unterraum. Gilt \(f(U) \subseteq U\), also \(f(u) \in U\) fuer alle \(u \in U\), so hei\ss t \(U\) ein \(f\)-invarianter Unterraum von \(V\).
